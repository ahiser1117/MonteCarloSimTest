{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrand\n",
    "from StatTests.MWTest import wilcoxon_test\n",
    "from StatTests.TTest import t_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE\n",
    "\n",
    "I couldn't find JAX implementations of the T Test or Wilcox Test so I had OpenAI's new `o3-mini-high` make quick implementations of them. I haven't checked the absolute accuracy of those implementations, but the numbers lined up with the numbers in Very Normal's (Christian) video so I'm just going with them. \n",
    "\n",
    "The main point of this was to show the difference in speed between JAX and R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreation of Christian's code but calling JAX functions\n",
    "\n",
    "def runReplication(key, test, shift, dist):\n",
    "    key1, key2 = jrand.split(key)\n",
    "    if dist == \"Normal\":\n",
    "        A = jrand.normal(key1, (27,)) * 1200 + 10500\n",
    "        B = jrand.normal(key2, (27,)) * 1200 + 10500 + shift\n",
    "    elif dist == \"Cauchy\":\n",
    "        A = jrand.cauchy(key1, (27,)) * 1200 + 10500\n",
    "        B = jrand.cauchy(key2, (27,)) * 1200 + 10500 + shift\n",
    "\n",
    "    if test == \"Student\":\n",
    "        _, p_value = t_test(A, B, equal_var=True)\n",
    "    elif test == \"Welch\":\n",
    "        _, p_value = t_test(A, B, equal_var=False)\n",
    "    elif test == \"Wilcox\":\n",
    "        _, p_value = wilcoxon_test(A, B)\n",
    "\n",
    "    return p_value < 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the options we want to test and call the function.\n",
    "\n",
    "`jax.vmap` is similar to the `pwalk` function in the video (a parallel map)\n",
    "\n",
    "`jrand.PRNGKey` initializes the RNG seed. It takes any integer (I chose 0)\n",
    "\n",
    "`jrand.split` creates `number_of_simulations` new keys(seeds) so that each call to `runReplication` has a unique seed.\n",
    "\n",
    "Here I've nested for loops over the `tests` and `dists` then nested `jax.vmap`s over the `shifts` and `number_of_simulations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [\"Student\", \"Welch\", \"Wilcox\"]\n",
    "dists = [\"Normal\", \"Cauchy\"]\n",
    "shifts = jnp.array([300, 600, 900])\n",
    "number_of_simulations = 1_000_000\n",
    "\n",
    "results = {}\n",
    "for test in tests:\n",
    "    results[test] = {}\n",
    "    for dist in dists:\n",
    "        results[test][dist] = jax.vmap(\n",
    "            lambda k: jax.vmap(lambda s: runReplication(k, test, s, dist))(\n",
    "                shifts\n",
    "            )\n",
    "        )(jrand.split(jrand.PRNGKey(0), number_of_simulations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I just format the results for printing out the average results for each test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power of Student test:\n",
      "with Cauchy distribution:\n",
      "Shift: 300, Power: 0.024\n",
      "Shift: 600, Power: 0.034\n",
      "Shift: 900, Power: 0.051\n",
      "with Normal distribution:\n",
      "Shift: 300, Power: 0.147\n",
      "Shift: 600, Power: 0.438\n",
      "Shift: 900, Power: 0.772\n",
      "Power of Welch test:\n",
      "with Cauchy distribution:\n",
      "Shift: 300, Power: 0.023\n",
      "Shift: 600, Power: 0.033\n",
      "Shift: 900, Power: 0.049\n",
      "with Normal distribution:\n",
      "Shift: 300, Power: 0.146\n",
      "Shift: 600, Power: 0.437\n",
      "Shift: 900, Power: 0.771\n",
      "Power of Wilcox test:\n",
      "with Cauchy distribution:\n",
      "Shift: 300, Power: 0.076\n",
      "Shift: 600, Power: 0.162\n",
      "Shift: 900, Power: 0.298\n",
      "with Normal distribution:\n",
      "Shift: 300, Power: 0.138\n",
      "Shift: 600, Power: 0.414\n",
      "Shift: 900, Power: 0.745\n"
     ]
    }
   ],
   "source": [
    "import jax.tree_util as jtu\n",
    "\n",
    "powers = jtu.tree_map(lambda v: jnp.mean(v, axis=0), results)\n",
    "\n",
    "for test in powers.keys():\n",
    "    print(f\"Power of {test} test:\")\n",
    "    for dist in powers[test].keys():\n",
    "        print(f\"with {dist} distribution:\")\n",
    "        for i, shift in enumerate(shifts):\n",
    "            print(f\"Shift: {shift}, Power: {powers[test][dist][i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
